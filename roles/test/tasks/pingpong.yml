- name: Install gnu 9 + openmpi (w/ ucx) + performance tools
  yum:
    name: ohpc-gnu9-openmpi4-perf-tools
    state: present
  become: yes
- name: Make directory
  file:
    path: "{{ jobdir }}"
    state: directory
    owner: "{{ ansible_user }}"
- name: Create sbatch script
  copy:
    dest: "{{ jobdir }}/ping.sh"
    content: |
      #!/usr/bin/bash

      #SBATCH --ntasks=2
      #SBATCH --ntasks-per-node=1
      #SBATCH --output=%x.out
      #SBATCH --error=%x.out
      #SBATCH --exclusive
      {%if openhpc_tests_nodes is defined %}#SBATCH --nodelist={{ openhpc_tests_nodes }}{% endif %}
      
      export UCX_NET_DEVICES={{ openhpc_tests_ucx_net_devices }}
      echo SLURM_JOB_NODELIST: $SLURM_JOB_NODELIST
      module load gnu9/9.3.0
      module load openmpi4/4.0.4
      module load imb/2019.6

      srun --mpi=pmix_v3 IMB-MPI1 pingpong
- name: Run pingpong
  shell: sbatch --wait ping.sh
  become: no
  args:
    chdir: "{{ jobdir }}"
- name: Read pingpong
  read_imb_pingpong:
    path: "{{ jobdir }}/ping.sh.out"
  register: ping_out
- name: Read nodes used
  shell: "grep 'SLURM_JOB_NODELIST:' {{ jobdir }}/ping.sh.out"
  register: run_nodes
- debug: 
    msg: |
      Summary for pingpong (2x scheduler-selected nodes):
      nodes: {{ run_nodes.stdout.split()[1] }}
      zero-size msg latency: {{ ping_out['columns']['latency'][0] }} us
      max bandwidth: {{ ping_out['columns']['bandwidth'] | max }} Mbytes/s
